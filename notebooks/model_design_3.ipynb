{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOPS project - Model design using MLFlow with an experiment function\n",
    "\n",
    "Author : **Nicolas Deronsart**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as french_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up MLFlow tracking to monitor the model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/638688685417919419', creation_time=1699969570525, experiment_id='638688685417919419', last_update_time=1699969570525, lifecycle_stage='active', name='model_design', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "mlflow.sklearn.autolog(log_datasets=False)\n",
    "mlflow.set_experiment(\"model_design\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training a first model, we need to get the training and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film-url</th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-135259/c...</td>\n",
       "      <td>Si vous cherchez du cinéma abrutissant à tous ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-172430/c...</td>\n",
       "      <td>Trash, re-trash et re-re-trash...! Une horreur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-15105/cr...</td>\n",
       "      <td>Et si, dans les 5 premières minutes du film, l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-188629/c...</td>\n",
       "      <td>Mon dieu ! Quelle métaphore filée ! Je suis ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-23514/cr...</td>\n",
       "      <td>Premier film de la saga Kozure Okami, \"Le Sabr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159995</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-132387/c...</td>\n",
       "      <td>Un rythme bien trop lent et un Ashton Kutcher ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159996</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-53313/cr...</td>\n",
       "      <td>Monsieur Duchovny vous êtes aussi piètre acteu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159997</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-248258/c...</td>\n",
       "      <td>Complètement différent des films de la série C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159998</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-268731/c...</td>\n",
       "      <td>Alors franchement pour le moment c'est le meil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159999</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-188871/c...</td>\n",
       "      <td>Beur sur la ville réunit à lui même toutes les...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 film-url  \\\n",
       "0       http://www.allocine.fr/film/fichefilm-135259/c...   \n",
       "1       http://www.allocine.fr/film/fichefilm-172430/c...   \n",
       "2       http://www.allocine.fr/film/fichefilm-15105/cr...   \n",
       "3       http://www.allocine.fr/film/fichefilm-188629/c...   \n",
       "4       http://www.allocine.fr/film/fichefilm-23514/cr...   \n",
       "...                                                   ...   \n",
       "159995  http://www.allocine.fr/film/fichefilm-132387/c...   \n",
       "159996  http://www.allocine.fr/film/fichefilm-53313/cr...   \n",
       "159997  http://www.allocine.fr/film/fichefilm-248258/c...   \n",
       "159998  http://www.allocine.fr/film/fichefilm-268731/c...   \n",
       "159999  http://www.allocine.fr/film/fichefilm-188871/c...   \n",
       "\n",
       "                                                   review  polarity  \n",
       "0       Si vous cherchez du cinéma abrutissant à tous ...         0  \n",
       "1       Trash, re-trash et re-re-trash...! Une horreur...         0  \n",
       "2       Et si, dans les 5 premières minutes du film, l...         0  \n",
       "3       Mon dieu ! Quelle métaphore filée ! Je suis ab...         0  \n",
       "4       Premier film de la saga Kozure Okami, \"Le Sabr...         1  \n",
       "...                                                   ...       ...  \n",
       "159995  Un rythme bien trop lent et un Ashton Kutcher ...         0  \n",
       "159996  Monsieur Duchovny vous êtes aussi piètre acteu...         0  \n",
       "159997  Complètement différent des films de la série C...         1  \n",
       "159998  Alors franchement pour le moment c'est le meil...         1  \n",
       "159999  Beur sur la ville réunit à lui même toutes les...         0  \n",
       "\n",
       "[160000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film-url</th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-51895/cr...</td>\n",
       "      <td>Ce film est tout ce qu'il y a de plus sympa. M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-272/crit...</td>\n",
       "      <td>The Wall a été réalisé par Alan Parker (Fame, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-60134/cr...</td>\n",
       "      <td>Encore un film majeur tres mal distribué, comm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-31396/cr...</td>\n",
       "      <td>L'idée est très bonne mais le film manque de r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-135195/c...</td>\n",
       "      <td>Un petit nanar rigolo a regarder. A voir une f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-39142/cr...</td>\n",
       "      <td>Ce petit film tourné en 18 jours pour la somme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-8171/cri...</td>\n",
       "      <td>Le roman de Forsyth, d'où est tiré le scénario...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-228026/c...</td>\n",
       "      <td>Qu'on aime ou pas \"Toni Erdmann\" - et au sorti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-219994/c...</td>\n",
       "      <td>Un film qui a fait un certain buzz médiatique,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-5762/cri...</td>\n",
       "      <td>C'est long, c'est mièvre, c'est ennuyeux tout ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                film-url  \\\n",
       "0      http://www.allocine.fr/film/fichefilm-51895/cr...   \n",
       "1      http://www.allocine.fr/film/fichefilm-272/crit...   \n",
       "2      http://www.allocine.fr/film/fichefilm-60134/cr...   \n",
       "3      http://www.allocine.fr/film/fichefilm-31396/cr...   \n",
       "4      http://www.allocine.fr/film/fichefilm-135195/c...   \n",
       "...                                                  ...   \n",
       "19995  http://www.allocine.fr/film/fichefilm-39142/cr...   \n",
       "19996  http://www.allocine.fr/film/fichefilm-8171/cri...   \n",
       "19997  http://www.allocine.fr/film/fichefilm-228026/c...   \n",
       "19998  http://www.allocine.fr/film/fichefilm-219994/c...   \n",
       "19999  http://www.allocine.fr/film/fichefilm-5762/cri...   \n",
       "\n",
       "                                                  review  polarity  \n",
       "0      Ce film est tout ce qu'il y a de plus sympa. M...         0  \n",
       "1      The Wall a été réalisé par Alan Parker (Fame, ...         1  \n",
       "2      Encore un film majeur tres mal distribué, comm...         1  \n",
       "3      L'idée est très bonne mais le film manque de r...         0  \n",
       "4      Un petit nanar rigolo a regarder. A voir une f...         0  \n",
       "...                                                  ...       ...  \n",
       "19995  Ce petit film tourné en 18 jours pour la somme...         1  \n",
       "19996  Le roman de Forsyth, d'où est tiré le scénario...         0  \n",
       "19997  Qu'on aime ou pas \"Toni Erdmann\" - et au sorti...         1  \n",
       "19998  Un film qui a fait un certain buzz médiatique,...         1  \n",
       "19999  C'est long, c'est mièvre, c'est ennuyeux tout ...         0  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv('../data/valid.csv')\n",
    "df_valid = df_valid.drop('Unnamed: 0', axis=1)\n",
    "df_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create a pipeline to train and predict the polaririty prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of an experiment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    dataset,\n",
    "    pipeline,\n",
    "    mlflow_run_tags = None,\n",
    "    mlflow_run_parameters = None,\n",
    "    mlflow_run_description = None,\n",
    "    validation_set = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a sentiment analysis model, print the evaluation result and store everything to MLFlow\n",
    "    @param: dataset: pandas dataframe containing the input training set\n",
    "    @param: pipeline: scikit-learn pipeline that will be applied to the input data\n",
    "    @param: mlflow_run_tags: dict of tags that will be stored in the MLFlow run\n",
    "    @param: mlflow_run_parameters: dict of parameters that will be stored in the MLFlow run\n",
    "    @param: mlflow_run_description: textual description of the run \n",
    "    @param: validation_set = None\n",
    "    @return: the ModelInfo of the model generated by MLFlow \n",
    "    \"\"\"\n",
    "    with mlflow.start_run(description=mlflow_run_description):\n",
    "        pipeline.fit(dataset['review'], dataset['polarity'])\n",
    "\n",
    "        mlflow.set_tags(mlflow_run_tags)\n",
    "\n",
    "        mlflow.log_params(mlflow_run_parameters)\n",
    "\n",
    "        if validation_set is not None:\n",
    "            y_pred = pipeline.predict(validation_set['review'])\n",
    "            \n",
    "            y_pred_proba = pipeline.predict_proba(validation_set['review'])\n",
    "            y_pred_proba = [x[1] for x in y_pred_proba]\n",
    "\n",
    "            y_true = validation_set['polarity']\n",
    "            \n",
    "            experiment_metrics = {\n",
    "                \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "                \"f1\": f1_score(y_true, y_pred),\n",
    "                \"precision\": precision_score(y_true, y_pred),\n",
    "                \"recall\": recall_score(y_true, y_pred),\n",
    "                \"roc_auc\":roc_auc_score(y_true, y_pred_proba)\n",
    "            }\n",
    "            mlflow.log_metrics(experiment_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with different models and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a good model we can try different models and hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can try with a simple logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/14 17:21:45 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('tfidf', TfidfVectorizer(stop_words=['sien', 'o', 'dixième', 'déja', 'dix-huit', 'devra',\n",
      "                            'tous', 'encore', 'treize', 'avait', 'ouias',\n",
      "                            'serait', 'toute', 'lesquels', 'auront', 'cela',\n",
      "                            'parce', 'parler', 'étant', 'mien', 'telle',\n",
      "                            'pourrait', 'seuls', 'donc', 'même', 'lesquelles',\n",
      "                            'doit', 'siennes', 'es', 'premier', ...])), ('model', LogisticRegression(m...`\n",
      "2023/11/14 17:21:45 WARNING mlflow.utils: Truncated the value of the key `tfidf__stop_words`. Truncated value: `['sien', 'o', 'dixième', 'déja', 'dix-huit', 'devra', 'tous', 'encore', 'treize', 'avait', 'ouias', 'serait', 'toute', 'lesquels', 'auront', 'cela', 'parce', 'parler', 'étant', 'mien', 'telle', 'pourrait', 'seuls', 'donc', 'même', 'lesquelles', 'doit', 'siennes', 'es', 'premier', 'en', 'si', 'celles-la', 'aurait', 'aie', 'antérieur', 'dessous', 'ses', 'huit', 'celui-la', 'telles', 'lui-meme', 'toi-meme', 'deja', 'antérieure', 'quinze', 'pas', 'revoici', 'derrière', 'merci', 'ouverte', 'tend',...`\n",
      "/Users/deronsart/anaconda3/envs/mlops/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "2023/11/14 17:22:18 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/deronsart/anaconda3/envs/mlops/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=list(french_stopwords))),\n",
    "    ('model', LogisticRegression(penalty='l2', C=1.0, max_iter=500, random_state=42))\n",
    "])\n",
    "\n",
    "build_model(\n",
    "    dataset=df,\n",
    "    pipeline=pipeline,\n",
    "    mlflow_run_tags={\n",
    "        \"vectorizer\": \"TfidfVectorizer\",\n",
    "        \"classifier\": \"LogisticRegression\",\n",
    "        \"mlflow.source.name\": \"model_design_3.ipynb\",\n",
    "        \"mlflow.note.content\": \"Sentiment analysis on movies reviews\",\n",
    "        \"mlflow.source.git.commit\": subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]),\n",
    "        \"dataset\": \"train.csv\",\n",
    "    },\n",
    "    mlflow_run_parameters={\n",
    "        \"penalty\": \"l2\",\n",
    "        \"C\": 1.0,\n",
    "        \"max_iter\": 500,\n",
    "        \"random_state\": 42,\n",
    "    },\n",
    "    mlflow_run_description=\"Logistic regression model with TF-IDF vectorization\",\n",
    "    validation_set=df_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try other hyperparameters for a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/14 17:22:20 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('tfidf', TfidfVectorizer(stop_words=['sien', 'o', 'dixième', 'déja', 'dix-huit', 'devra',\n",
      "                            'tous', 'encore', 'treize', 'avait', 'ouias',\n",
      "                            'serait', 'toute', 'lesquels', 'auront', 'cela',\n",
      "                            'parce', 'parler', 'étant', 'mien', 'telle',\n",
      "                            'pourrait', 'seuls', 'donc', 'même', 'lesquelles',\n",
      "                            'doit', 'siennes', 'es', 'premier', ...])), ('model', LogisticRegression(C...`\n",
      "2023/11/14 17:22:20 WARNING mlflow.utils: Truncated the value of the key `tfidf__stop_words`. Truncated value: `['sien', 'o', 'dixième', 'déja', 'dix-huit', 'devra', 'tous', 'encore', 'treize', 'avait', 'ouias', 'serait', 'toute', 'lesquels', 'auront', 'cela', 'parce', 'parler', 'étant', 'mien', 'telle', 'pourrait', 'seuls', 'donc', 'même', 'lesquelles', 'doit', 'siennes', 'es', 'premier', 'en', 'si', 'celles-la', 'aurait', 'aie', 'antérieur', 'dessous', 'ses', 'huit', 'celui-la', 'telles', 'lui-meme', 'toi-meme', 'deja', 'antérieure', 'quinze', 'pas', 'revoici', 'derrière', 'merci', 'ouverte', 'tend',...`\n",
      "/Users/deronsart/anaconda3/envs/mlops/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=list(french_stopwords))),\n",
    "    ('model', LogisticRegression(penalty='l1', solver='liblinear', C=10, max_iter=500, random_state=42))\n",
    "])\n",
    "\n",
    "build_model(\n",
    "    dataset=df,\n",
    "    pipeline=pipeline,\n",
    "    mlflow_run_tags={\n",
    "        \"vectorizer\": \"TfidfVectorizer\",\n",
    "        \"classifier\": \"LogisticRegression\",\n",
    "        \"mlflow.source.name\": \"model_design_3.ipynb\",\n",
    "        \"mlflow.note.content\": \"Sentiment analysis on movies reviews\",\n",
    "        \"mlflow.source.git.commit\": subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]),\n",
    "        \"dataset\": \"train.csv\",\n",
    "    },\n",
    "    mlflow_run_parameters={\n",
    "        \"penalty\": \"l2\",\n",
    "        \"solver\": \"liblinear\",\n",
    "        \"C\": 1.0,\n",
    "        \"max_iter\": 500,\n",
    "        \"random_state\": 42,\n",
    "    },\n",
    "    mlflow_run_description=\"Logistic regression model with TF-IDF vectorization\",\n",
    "    validation_set=df_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also try with a mutlinomial naive bayes model. First with the default hyperparameter alpha = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/14 17:22:51 WARNING mlflow.utils: Truncated the value of the key `tfidf__stop_words`. Truncated value: `['sien', 'o', 'dixième', 'déja', 'dix-huit', 'devra', 'tous', 'encore', 'treize', 'avait', 'ouias', 'serait', 'toute', 'lesquels', 'auront', 'cela', 'parce', 'parler', 'étant', 'mien', 'telle', 'pourrait', 'seuls', 'donc', 'même', 'lesquelles', 'doit', 'siennes', 'es', 'premier', 'en', 'si', 'celles-la', 'aurait', 'aie', 'antérieur', 'dessous', 'ses', 'huit', 'celui-la', 'telles', 'lui-meme', 'toi-meme', 'deja', 'antérieure', 'quinze', 'pas', 'revoici', 'derrière', 'merci', 'ouverte', 'tend',...`\n",
      "/Users/deronsart/anaconda3/envs/mlops/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/deronsart/anaconda3/envs/mlops/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=list(french_stopwords))),\n",
    "    ('model', MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "build_model(\n",
    "    dataset=df,\n",
    "    pipeline=pipeline,\n",
    "    mlflow_run_tags={\n",
    "        \"vectorizer\": \"TfidfVectorizer\",\n",
    "        \"classifier\": \"MultinomialNB\",\n",
    "        \"mlflow.source.name\": \"model_design_3.ipynb\",\n",
    "        \"mlflow.note.content\": \"Sentiment analysis on movies reviews\",\n",
    "        \"mlflow.source.git.commit\": subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]),\n",
    "        \"dataset\": \"train.csv\",\n",
    "    },\n",
    "    mlflow_run_parameters={\n",
    "        \"alpha\": 1.0,\n",
    "        \"force_alpha\": \"warn\",\n",
    "    },\n",
    "    mlflow_run_description=\"Multinomial Naive Bayes model with TF-IDF vectorization\",\n",
    "    validation_set=df_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then with another value for alpha : 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/14 17:23:20 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('tfidf', TfidfVectorizer(stop_words=['sien', 'o', 'dixième', 'déja', 'dix-huit', 'devra',\n",
      "                            'tous', 'encore', 'treize', 'avait', 'ouias',\n",
      "                            'serait', 'toute', 'lesquels', 'auront', 'cela',\n",
      "                            'parce', 'parler', 'étant', 'mien', 'telle',\n",
      "                            'pourrait', 'seuls', 'donc', 'même', 'lesquelles',\n",
      "                            'doit', 'siennes', 'es', 'premier', ...])), ('model', MultinomialNB(alpha=...`\n",
      "2023/11/14 17:23:20 WARNING mlflow.utils: Truncated the value of the key `tfidf__stop_words`. Truncated value: `['sien', 'o', 'dixième', 'déja', 'dix-huit', 'devra', 'tous', 'encore', 'treize', 'avait', 'ouias', 'serait', 'toute', 'lesquels', 'auront', 'cela', 'parce', 'parler', 'étant', 'mien', 'telle', 'pourrait', 'seuls', 'donc', 'même', 'lesquelles', 'doit', 'siennes', 'es', 'premier', 'en', 'si', 'celles-la', 'aurait', 'aie', 'antérieur', 'dessous', 'ses', 'huit', 'celui-la', 'telles', 'lui-meme', 'toi-meme', 'deja', 'antérieure', 'quinze', 'pas', 'revoici', 'derrière', 'merci', 'ouverte', 'tend',...`\n",
      "/Users/deronsart/anaconda3/envs/mlops/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Users/deronsart/anaconda3/envs/mlops/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=list(french_stopwords))),\n",
    "    ('model', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "\n",
    "build_model(\n",
    "    dataset=df,\n",
    "    pipeline=pipeline,\n",
    "    mlflow_run_tags={\n",
    "        \"vectorizer\": \"TfidfVectorizer\",\n",
    "        \"classifier\": \"MultinomialNB\",\n",
    "        \"mlflow.source.name\": \"model_design_3.ipynb\",\n",
    "        \"mlflow.note.content\": \"Sentiment analysis on movies reviews\",\n",
    "        \"mlflow.source.git.commit\": subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]),\n",
    "        \"dataset\": \"train.csv\",\n",
    "    },\n",
    "    mlflow_run_parameters={\n",
    "        \"alpha\": 0.1,\n",
    "        \"force_alpha\": \"warn\",\n",
    "    },\n",
    "    mlflow_run_description=\"Multinomial Naive Bayes model with TF-IDF vectorization\",\n",
    "    validation_set=df_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the results of the different models in the MLFlow application, we can see that the best model between the ones we tried is the logistic regression model with the hyperparameter C = 1 and the penalty \"l2\". Indeed we have an accuracy on the validation set of :\n",
    "* 0.919 for the logistic regression model with the hyperparameter C = 1 and the penalty \"l2\";\n",
    "* 0.911 for the logistic regression model with the hyperparameter C = 10 and the penalty \"l1\";\n",
    "* 0.897 for the multinomial naive Bayes model with the hyperparameter alpha = 1;\n",
    "* 0.891 for the multinomial naive Bayes model with the hyperparameter alpha = 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, space_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    dataset,\n",
    "    pipeline,\n",
    "    mlflow_run_tags = None,\n",
    "    mlflow_run_parameters = None,\n",
    "    mlflow_run_description = None,\n",
    "    validation_set = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a sentiment analysis model, print the evaluation result and store everything to MLFlow\n",
    "    @param: dataset: pandas dataframe containing the input training set\n",
    "    @param: pipeline: scikit-learn pipeline that will be applied to the input data\n",
    "    @param: mlflow_run_tags: dict of tags that will be stored in the MLFlow run\n",
    "    @param: mlflow_run_parameters: dict of parameters that will be stored in the MLFlow run\n",
    "    @param: mlflow_run_description: textual description of the run \n",
    "    @param: validation_set = None\n",
    "    @return: the ModelInfo of the model generated by MLFlow \n",
    "    \"\"\"\n",
    "    with mlflow.start_run(description=mlflow_run_description):\n",
    "        pipeline.fit(dataset['review'], dataset['polarity'])\n",
    "\n",
    "        mlflow.set_tags(mlflow_run_tags)\n",
    "\n",
    "        mlflow.log_params(mlflow_run_parameters)\n",
    "\n",
    "        if validation_set is not None:\n",
    "            y_pred = pipeline.predict(validation_set['review'])\n",
    "            \n",
    "            y_pred_proba = pipeline.predict_proba(validation_set['review'])\n",
    "            y_pred_proba = [x[1] for x in y_pred_proba]\n",
    "\n",
    "            y_true = validation_set['polarity']\n",
    "            \n",
    "            experiment_metrics = {\n",
    "                \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "                \"f1\": f1_score(y_true, y_pred),\n",
    "                \"precision\": precision_score(y_true, y_pred),\n",
    "                \"recall\": recall_score(y_true, y_pred),\n",
    "                \"roc_auc\":roc_auc_score(y_true, y_pred_proba)\n",
    "            }\n",
    "            mlflow.log_metrics(experiment_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \"\"\"\n",
    "    Objective function for the hyperopt optimization\n",
    "    @param: params: dict of parameters to test\n",
    "    @return: dict of results\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words=list(french_stopwords))),\n",
    "        ('model', LogisticRegression(**params))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(df['review'], df['polarity'])\n",
    "    \n",
    "    y_pred = pipeline.predict(df_valid['review'])\n",
    "    \n",
    "    return -f1_score(df_valid['polarity'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "    'C': hp.uniform('C', 0.0, 10.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPE is being used as the default algorithm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: objective() missing 1 required positional argument: 'params'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "objective() missing 1 required positional argument: 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/deronsart/Documents/Master/M2 ML/S1/MLOPS/Project/mlops_project/notebooks/model_design_3.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/deronsart/Documents/Master/M2%20ML/S1/MLOPS/Project/mlops_project/notebooks/model_design_3.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fmin(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/deronsart/Documents/Master/M2%20ML/S1/MLOPS/Project/mlops_project/notebooks/model_design_3.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     fn\u001b[39m=\u001b[39;49mobjective,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/deronsart/Documents/Master/M2%20ML/S1/MLOPS/Project/mlops_project/notebooks/model_design_3.ipynb#X55sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     space\u001b[39m=\u001b[39;49mspace,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/deronsart/Documents/Master/M2%20ML/S1/MLOPS/Project/mlops_project/notebooks/model_design_3.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     max_evals\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/deronsart/Documents/Master/M2%20ML/S1/MLOPS/Project/mlops_project/notebooks/model_design_3.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[1;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[1;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[1;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "\u001b[0;31mTypeError\u001b[0m: objective() missing 1 required positional argument: 'params'"
     ]
    }
   ],
   "source": [
    "fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    max_evals=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
